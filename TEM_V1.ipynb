{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TEM_V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1unVoOegdaCrLntqvhFB6yXS-73Sf9u8f",
      "authorship_tag": "ABX9TyOP6FnOLh8ULNZ+K0qEdiLR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ftrova1/Dataset_TEM/blob/master/TEM_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMh7BP7C1wTo",
        "colab_type": "code",
        "outputId": "b4dd3797-5257-48b8-8ecb-f392d3852d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRiVyq1Y31Xt",
        "colab_type": "code",
        "outputId": "914196f9-5817-45a7-a3d6-b444d0deb076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls '/content/drive/My Drive/Coding/Projects/TEM'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWA8Y69r90zT",
        "colab_type": "code",
        "outputId": "7005ce3c-f7b2-43e5-f152-5e52c7b90c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Imports\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import adam\n",
        "from keras import backend as K\n",
        "\n",
        "## Seeding \n",
        "seed = 2020\n",
        "random.seed = seed\n",
        "np.random.seed = seed\n",
        "tf.seed = seed"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpb7mdk0917r",
        "colab_type": "code",
        "outputId": "fcad3146-a059-4d74-8a5b-8242e8ab49bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "img = cv2.imread('/content/drive/My Drive/Coding/Projects/TEM/train/10_B1_19000x/data/10_B1_19000x.tif')\n",
        "mask = cv2.imread('/content/drive/My Drive/Coding/Projects/TEM/train/10_B1_19000x/masks/10_B1_19000x.tif_segmentation.tifnormalized.tif')\n",
        "fig = plt.figure()\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(img)\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.imshow(mask)\n",
        "#print (np.unique(mask))\n",
        "#print(np.unique(mask), mask.shape, img.shape)\n",
        "#mask = mask / 255\n",
        "\n",
        "print (mask.shape)\n",
        "print (np.unique(mask))\n",
        "\n",
        "#mask_cat = tf.keras.utils.to_categorical(mask,3)\n",
        "#print (mask_cat[:,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1024, 1024, 3)\n",
            "[ 85 170 255]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAACuCAYAAAAyCKoKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDhgMOdwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXT8YZ9C-Au1",
        "colab_type": "code",
        "outputId": "d48fbe6a-04a9-4bba-9d54-bcfb8cccb6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def uniq(lst):\n",
        "    last = object()\n",
        "    for item in lst:\n",
        "        if item == last:\n",
        "            continue\n",
        "        yield item\n",
        "        last = item\n",
        "        \n",
        "def sort_deduplicate(l):\n",
        "    return uniq(sorted(l, reverse=True))\n",
        "\n",
        "lista = []\n",
        "for i in range(1024):\n",
        "    for j in range(1024):\n",
        "        lista.append(mask[i,j,:].tolist())\n",
        "\n",
        "palette_gen = sort_deduplicate(lista)\n",
        "palette = []\n",
        "for item in palette_gen:\n",
        "    palette.append(item)\n",
        "    \n",
        "palette"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[255, 255, 255], [170, 170, 170], [85, 85, 85]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a6h8_TX-HFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DataGen(keras.utils.Sequence):\n",
        "    def __init__(self, ids, path, masks_dict, batch_size=8, image_size=256, data_path = 'data', masks_path = 'masks'):\n",
        "        self.ids = ids\n",
        "        self.path = path\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.masks_dict = masks_dict\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __load__(self, id_name):\n",
        "        image_path = os.path.join(self.path, id_name, \"data\", id_name) + '.tif'\n",
        "        ## Reading Image\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "        image = image/255.0\n",
        "        mask = self.masks_dict[id_name]\n",
        "\n",
        "        return image, mask\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        if(index+1)*self.batch_size > len(self.ids):\n",
        "            self.batch_size = len(self.ids) - index*self.batch_size\n",
        "        \n",
        "        files_batch = self.ids[index*self.batch_size : (index+1)*self.batch_size]\n",
        "        \n",
        "        image = []\n",
        "        mask  = []\n",
        "        \n",
        "        for id_name in files_batch:\n",
        "            _img, _mask = self.__load__(id_name)\n",
        "            image.append(_img)\n",
        "            mask.append(_mask)\n",
        "            \n",
        "        image = np.array(image)\n",
        "        mask  = np.array(mask)\n",
        "\n",
        "        return image, mask\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        pass\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.ids)/float(self.batch_size)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJlSgdJM-SI6",
        "colab_type": "code",
        "outputId": "8e7d9dcc-d4c0-465b-ed73-638d8a3dd3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image_size = 256\n",
        "train_path = \"/content/drive/My Drive/Coding/Projects/TEM/train/\"\n",
        "validation_path = \"/content/drive/My Drive/Coding/Projects/TEM/test/\"\n",
        "epochs = 400\n",
        "batch_size = 4\n",
        "\n",
        "## Training Ids\n",
        "train_ids = next(os.walk(train_path))[1]\n",
        "#print(train_ids)\n",
        "\n",
        "train_masks_dict = {}    \n",
        "test_masks_dict = {} \n",
        "\n",
        "## Validation Ids\n",
        "valid_ids = next(os.walk(validation_path))[1]\n",
        "\n",
        "valid_ids = valid_ids[:]\n",
        "train_ids = train_ids[:]\n",
        "\n",
        "for train_id in train_ids:\n",
        "    mask_path = os.path.join(train_path, train_id, \"masks/\")\n",
        "\n",
        "    _mask_path = mask_path + train_id + '.tif_segmentation.tifnormalized.tif'\n",
        "    _mask_image = cv2.imread(_mask_path)\n",
        "    _mask_image = cv2.resize(_mask_image, (image_size, image_size)) \n",
        "    mask = _mask_image\n",
        "\n",
        "    one_hot_map = []\n",
        "    for colour in palette:\n",
        "        class_map = tf.reduce_all (tf.equal(mask,colour), axis=-1)\n",
        "        one_hot_map.append(class_map)\n",
        "    one_hot_map = tf.stack(one_hot_map, axis = -1)\n",
        "    one_hot_map = tf.cast(one_hot_map, tf.float32)\n",
        "    \n",
        "    train_masks_dict[train_id] = np.asarray(one_hot_map)\n",
        "    #cv2.imwrite('/content/drive/My Drive/Coding/Projects/TEM/prova_maschera.png', np.float32(one_hot_map))\n",
        "    #break\n",
        "    \n",
        "\n",
        "for test_id in valid_ids:\n",
        "    mask_path = os.path.join(validation_path, test_id, \"masks/\")\n",
        "\n",
        "    _mask_path = mask_path + test_id + '.tif_segmentation.tifnormalized.tif'\n",
        "    _mask_image = cv2.imread(_mask_path)\n",
        "    _mask_image = cv2.resize(_mask_image, (image_size, image_size)) \n",
        "    mask = _mask_image\n",
        "\n",
        "    one_hot_map = []\n",
        "    for colour in palette:\n",
        "        class_map = tf.reduce_all (tf.equal(mask,colour), axis=-1)\n",
        "        one_hot_map.append(class_map)\n",
        "    one_hot_map = tf.stack(one_hot_map, axis = -1)\n",
        "    one_hot_map = tf.cast(one_hot_map, tf.float32)\n",
        "    \n",
        "    test_masks_dict[test_id] = np.asarray(one_hot_map)\n",
        "    #break\n",
        "\n",
        "print (len(train_masks_dict),len(test_masks_dict))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "454 193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9n6cAhD4QDCU",
        "colab_type": "code",
        "outputId": "3725d705-701f-4a2a-ead7-c6e52643a493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "img2 = cv2.imread(\"/content/drive/My Drive/Coding/Projects/TEM/prova_maschera.png\")\n",
        "print (img2.shape)\n",
        "img3 = train_masks_dict['100_C1_19000x']\n",
        "print (img3.shape)\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(img2)\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.imshow(img3)\n",
        "\n",
        "plt.imsave('/content/drive/My Drive/Coding/Projects/TEM/prova_maschera2.png', np.asarray(img3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(256, 256, 3)\n",
            "(256, 256, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAACuCAYAAADNhk2tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FihMmUxkcIa",
        "colab_type": "code",
        "outputId": "94410702-1ec4-41a3-bc9e-40eb2d4b7e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "img4 = cv2.imread('/content/drive/My Drive/Coding/Projects/TEM/prova_maschera2.png')\n",
        "plt.imshow(img4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcea623d358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5dwy19Z-dtv",
        "colab_type": "code",
        "outputId": "f08755c6-93d6-4214-c8ab-76410a32b16e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gen = DataGen(train_ids, train_path, train_masks_dict ,batch_size=batch_size, image_size=image_size)\n",
        "x, y = gen.__getitem__(0)\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 256, 256, 3) (4, 256, 256, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_JGw0S-BGad",
        "colab_type": "code",
        "outputId": "5af05493-b72b-4a68-919a-ebd08876709d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "r = random.randint(0, len(x)-1)\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(x[r])\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.imshow(y[r])\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 256, 256, 3) (4, 256, 256, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAACuCAYAAADNhk2tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABKCuUTU48AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_jMq4OeBhXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    c = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    p = tf.keras.layers.MaxPool2D((2, 2), (2, 2))(c)\n",
        "    return c, p\n",
        "\n",
        "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    us = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "    concat = tf.keras.layers.Concatenate()([us, skip])\n",
        "    c = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
        "    c = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    return c\n",
        "\n",
        "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
        "    c = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
        "    c = tf.keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
        "    return c"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cz1w8HjBjzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def UNet():\n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    inputs = keras.layers.Input((image_size, image_size, 3))\n",
        "    \n",
        "    p0 = inputs\n",
        "    c1, p1 = down_block(p0, f[0]) #128 -> 64\n",
        "    c2, p2 = down_block(p1, f[1]) #64 -> 32\n",
        "    c3, p3 = down_block(p2, f[2]) #32 -> 16\n",
        "    c4, p4 = down_block(p3, f[3]) #16->8\n",
        "    \n",
        "    bn = bottleneck(p4, f[4])\n",
        "    \n",
        "    u1 = up_block(bn, c4, f[3]) #8 -> 16\n",
        "    u2 = up_block(u1, c3, f[2]) #16 -> 32\n",
        "    u3 = up_block(u2, c2, f[1]) #32 -> 64\n",
        "    u4 = up_block(u3, c1, f[0]) #64 -> 128\n",
        "    \n",
        "    outputs = keras.layers.Conv2D(3, (1, 1), padding=\"same\", activation=\"softmax\")(u4)\n",
        "    model = keras.models.Model(inputs, outputs)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuNMNNeVBmN7",
        "colab_type": "code",
        "outputId": "5bd344cd-1924-416b-ee5b-f5ac2829f8da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    intersection = K.sum(K.abs(y_true*y_pred ), axis=-1)\n",
        "    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1-dice_coef(y_true, y_pred)\n",
        "\n",
        "model = UNet()\n",
        "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 256, 256, 16) 448         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 256, 256, 16) 2320        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 128, 128, 16) 0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 128, 128, 32) 4640        max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 64, 64, 64)   18496       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 128)  73856       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_4 (UpSampling2D)  (None, 32, 32, 256)  0           conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 32, 32, 384)  0           up_sampling2d_4[0][0]            \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 32, 32, 128)  442496      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_5 (UpSampling2D)  (None, 64, 64, 128)  0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 64, 64, 192)  0           up_sampling2d_5[0][0]            \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 64, 64, 64)   110656      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_6 (UpSampling2D)  (None, 128, 128, 64) 0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 128, 128, 96) 0           up_sampling2d_6[0][0]            \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 128, 128, 32) 27680       concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_7 (UpSampling2D)  (None, 256, 256, 32) 0           conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 256, 256, 48) 0           up_sampling2d_7[0][0]            \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 256, 256, 16) 6928        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 256, 256, 16) 2320        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 256, 256, 3)  51          conv2d_36[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,962,659\n",
            "Trainable params: 1,962,659\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKN-NniUBoa6",
        "colab_type": "code",
        "outputId": "eb0b999d-a2bc-4519-c94d-663e688ae526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_gen = DataGen(train_ids, train_path, train_masks_dict, image_size=image_size, batch_size=batch_size)\n",
        "valid_gen = DataGen(valid_ids, validation_path, test_masks_dict, image_size=image_size, batch_size=batch_size)\n",
        "\n",
        "train_steps = len(train_ids)//batch_size\n",
        "valid_steps = len(valid_ids)//batch_size\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('unet_tem.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
        "model.fit(train_gen, validation_data=valid_gen, validation_steps=valid_steps, \n",
        "                    epochs=epochs, callbacks=[model_checkpoint])\n",
        "#model.load_weights('unet_tem.hdf5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 114 steps, validate for 48 steps\n",
            "Epoch 1/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.1355 - accuracy: 0.9400\n",
            "Epoch 00001: loss improved from inf to 0.13477, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 6s 52ms/step - loss: 0.1361 - accuracy: 0.9399 - val_loss: 0.1801 - val_accuracy: 0.9229\n",
            "Epoch 2/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.1467 - accuracy: 0.9347\n",
            "Epoch 00002: loss did not improve from 0.13477\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.1469 - accuracy: 0.9344 - val_loss: 0.1848 - val_accuracy: 0.9279\n",
            "Epoch 3/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.1415 - accuracy: 0.9403\n",
            "Epoch 00003: loss did not improve from 0.13477\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1414 - accuracy: 0.9402 - val_loss: 0.1568 - val_accuracy: 0.9345\n",
            "Epoch 4/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9314\n",
            "Epoch 00004: loss did not improve from 0.13477\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.1616 - accuracy: 0.9313 - val_loss: 0.1901 - val_accuracy: 0.9188\n",
            "Epoch 5/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.1779 - accuracy: 0.9264\n",
            "Epoch 00005: loss did not improve from 0.13477\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1763 - accuracy: 0.9269 - val_loss: 0.2001 - val_accuracy: 0.9231\n",
            "Epoch 6/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.1752 - accuracy: 0.9239\n",
            "Epoch 00006: loss did not improve from 0.13477\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1764 - accuracy: 0.9238 - val_loss: 0.2387 - val_accuracy: 0.9061\n",
            "Epoch 7/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1542 - accuracy: 0.9332\n",
            "Epoch 00007: loss did not improve from 0.13477\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1548 - accuracy: 0.9328 - val_loss: 0.1524 - val_accuracy: 0.9365\n",
            "Epoch 8/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.1319 - accuracy: 0.9431\n",
            "Epoch 00008: loss improved from 0.13477 to 0.13144, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.1314 - accuracy: 0.9431 - val_loss: 0.1476 - val_accuracy: 0.9388\n",
            "Epoch 9/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.1261 - accuracy: 0.9459\n",
            "Epoch 00009: loss improved from 0.13144 to 0.12866, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.1287 - accuracy: 0.9451 - val_loss: 0.1426 - val_accuracy: 0.9401\n",
            "Epoch 10/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1259 - accuracy: 0.9456\n",
            "Epoch 00010: loss improved from 0.12866 to 0.12588, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.1259 - accuracy: 0.9456 - val_loss: 0.1566 - val_accuracy: 0.9339\n",
            "Epoch 11/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1062 - accuracy: 0.9533\n",
            "Epoch 00011: loss improved from 0.12588 to 0.10720, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1072 - accuracy: 0.9528 - val_loss: 0.1610 - val_accuracy: 0.9342\n",
            "Epoch 12/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.1157 - accuracy: 0.9483\n",
            "Epoch 00012: loss did not improve from 0.10720\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1161 - accuracy: 0.9482 - val_loss: 0.1464 - val_accuracy: 0.9390\n",
            "Epoch 13/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1027 - accuracy: 0.9537\n",
            "Epoch 00013: loss improved from 0.10720 to 0.10209, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.1021 - accuracy: 0.9539 - val_loss: 0.1387 - val_accuracy: 0.9433\n",
            "Epoch 14/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1305 - accuracy: 0.9436\n",
            "Epoch 00014: loss did not improve from 0.10209\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1299 - accuracy: 0.9439 - val_loss: 0.1605 - val_accuracy: 0.9349\n",
            "Epoch 15/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.1145 - accuracy: 0.9505\n",
            "Epoch 00015: loss did not improve from 0.10209\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1152 - accuracy: 0.9504 - val_loss: 0.1389 - val_accuracy: 0.9441\n",
            "Epoch 16/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 0.9587\n",
            "Epoch 00016: loss improved from 0.10209 to 0.09401, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0940 - accuracy: 0.9581 - val_loss: 0.1507 - val_accuracy: 0.9359\n",
            "Epoch 17/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0875 - accuracy: 0.9603\n",
            "Epoch 00017: loss improved from 0.09401 to 0.08722, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0872 - accuracy: 0.9605 - val_loss: 0.1406 - val_accuracy: 0.9445\n",
            "Epoch 18/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0903 - accuracy: 0.9601\n",
            "Epoch 00018: loss did not improve from 0.08722\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0898 - accuracy: 0.9603 - val_loss: 0.1714 - val_accuracy: 0.9386\n",
            "Epoch 19/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0836 - accuracy: 0.9615\n",
            "Epoch 00019: loss improved from 0.08722 to 0.08332, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0833 - accuracy: 0.9617 - val_loss: 0.1465 - val_accuracy: 0.9425\n",
            "Epoch 20/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0761 - accuracy: 0.9656\n",
            "Epoch 00020: loss improved from 0.08332 to 0.07602, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0760 - accuracy: 0.9656 - val_loss: 0.1437 - val_accuracy: 0.9415\n",
            "Epoch 21/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0795 - accuracy: 0.9636\n",
            "Epoch 00021: loss did not improve from 0.07602\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0790 - accuracy: 0.9637 - val_loss: 0.1753 - val_accuracy: 0.9365\n",
            "Epoch 22/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.2038 - accuracy: 0.9166\n",
            "Epoch 00022: loss did not improve from 0.07602\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.2046 - accuracy: 0.9158 - val_loss: 0.3325 - val_accuracy: 0.8629\n",
            "Epoch 23/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.2101 - accuracy: 0.9167\n",
            "Epoch 00023: loss did not improve from 0.07602\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.2100 - accuracy: 0.9167 - val_loss: 0.1518 - val_accuracy: 0.9368\n",
            "Epoch 24/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.1433 - accuracy: 0.9391\n",
            "Epoch 00024: loss did not improve from 0.07602\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1432 - accuracy: 0.9390 - val_loss: 0.1535 - val_accuracy: 0.9374\n",
            "Epoch 25/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.1369 - accuracy: 0.9455\n",
            "Epoch 00025: loss did not improve from 0.07602\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1354 - accuracy: 0.9459 - val_loss: 0.1593 - val_accuracy: 0.9326\n",
            "Epoch 26/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.1013 - accuracy: 0.9563\n",
            "Epoch 00026: loss did not improve from 0.07602\n",
            "114/114 [==============================] - 3s 31ms/step - loss: 0.1023 - accuracy: 0.9560 - val_loss: 0.1384 - val_accuracy: 0.9403\n",
            "Epoch 27/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0962 - accuracy: 0.9579\n",
            "Epoch 00027: loss did not improve from 0.07602\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0954 - accuracy: 0.9582 - val_loss: 0.1749 - val_accuracy: 0.9366\n",
            "Epoch 28/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0980 - accuracy: 0.9570\n",
            "Epoch 00028: loss did not improve from 0.07602\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0979 - accuracy: 0.9570 - val_loss: 0.1325 - val_accuracy: 0.9435\n",
            "Epoch 29/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0706 - accuracy: 0.9684\n",
            "Epoch 00029: loss improved from 0.07602 to 0.07105, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0710 - accuracy: 0.9682 - val_loss: 0.1303 - val_accuracy: 0.9479\n",
            "Epoch 30/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0649 - accuracy: 0.9701\n",
            "Epoch 00030: loss improved from 0.07105 to 0.06650, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0665 - accuracy: 0.9697 - val_loss: 0.1415 - val_accuracy: 0.9439\n",
            "Epoch 31/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 0.9663\n",
            "Epoch 00031: loss did not improve from 0.06650\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0756 - accuracy: 0.9664 - val_loss: 0.1454 - val_accuracy: 0.9429\n",
            "Epoch 32/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0826 - accuracy: 0.9645\n",
            "Epoch 00032: loss did not improve from 0.06650\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0827 - accuracy: 0.9644 - val_loss: 0.1276 - val_accuracy: 0.9484\n",
            "Epoch 33/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9699\n",
            "Epoch 00033: loss improved from 0.06650 to 0.06461, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0646 - accuracy: 0.9700 - val_loss: 0.1286 - val_accuracy: 0.9498\n",
            "Epoch 34/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0575 - accuracy: 0.9733\n",
            "Epoch 00034: loss improved from 0.06461 to 0.05732, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0573 - accuracy: 0.9733 - val_loss: 0.1430 - val_accuracy: 0.9489\n",
            "Epoch 35/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0558 - accuracy: 0.9739\n",
            "Epoch 00035: loss improved from 0.05732 to 0.05619, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0562 - accuracy: 0.9737 - val_loss: 0.1281 - val_accuracy: 0.9504\n",
            "Epoch 36/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0509 - accuracy: 0.9758\n",
            "Epoch 00036: loss improved from 0.05619 to 0.05074, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0507 - accuracy: 0.9759 - val_loss: 0.1241 - val_accuracy: 0.9513\n",
            "Epoch 37/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0456 - accuracy: 0.9780\n",
            "Epoch 00037: loss improved from 0.05074 to 0.04601, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0460 - accuracy: 0.9778 - val_loss: 0.1280 - val_accuracy: 0.9524\n",
            "Epoch 38/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0983 - accuracy: 0.9600\n",
            "Epoch 00038: loss did not improve from 0.04601\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0980 - accuracy: 0.9601 - val_loss: 0.1644 - val_accuracy: 0.9301\n",
            "Epoch 39/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0994 - accuracy: 0.9578\n",
            "Epoch 00039: loss did not improve from 0.04601\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0994 - accuracy: 0.9578 - val_loss: 0.1569 - val_accuracy: 0.9415\n",
            "Epoch 40/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9725\n",
            "Epoch 00040: loss did not improve from 0.04601\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0605 - accuracy: 0.9726 - val_loss: 0.1474 - val_accuracy: 0.9498\n",
            "Epoch 41/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9766\n",
            "Epoch 00041: loss did not improve from 0.04601\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0492 - accuracy: 0.9766 - val_loss: 0.1415 - val_accuracy: 0.9507\n",
            "Epoch 42/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0469 - accuracy: 0.9774\n",
            "Epoch 00042: loss did not improve from 0.04601\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0469 - accuracy: 0.9774 - val_loss: 0.1305 - val_accuracy: 0.9503\n",
            "Epoch 43/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0635 - accuracy: 0.9708\n",
            "Epoch 00043: loss did not improve from 0.04601\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0631 - accuracy: 0.9709 - val_loss: 0.1405 - val_accuracy: 0.9444\n",
            "Epoch 44/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9779\n",
            "Epoch 00044: loss did not improve from 0.04601\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0462 - accuracy: 0.9778 - val_loss: 0.1329 - val_accuracy: 0.9542\n",
            "Epoch 45/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0409 - accuracy: 0.9798\n",
            "Epoch 00045: loss improved from 0.04601 to 0.04080, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0408 - accuracy: 0.9799 - val_loss: 0.1554 - val_accuracy: 0.9525\n",
            "Epoch 46/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9779\n",
            "Epoch 00046: loss did not improve from 0.04080\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0466 - accuracy: 0.9779 - val_loss: 0.1440 - val_accuracy: 0.9499\n",
            "Epoch 47/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1032 - accuracy: 0.9614\n",
            "Epoch 00047: loss did not improve from 0.04080\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1058 - accuracy: 0.9604 - val_loss: 0.2392 - val_accuracy: 0.8998\n",
            "Epoch 48/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.9386\n",
            "Epoch 00048: loss did not improve from 0.04080\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.1544 - accuracy: 0.9388 - val_loss: 0.1348 - val_accuracy: 0.9466\n",
            "Epoch 49/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0837 - accuracy: 0.9646\n",
            "Epoch 00049: loss did not improve from 0.04080\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0840 - accuracy: 0.9646 - val_loss: 0.1508 - val_accuracy: 0.9455\n",
            "Epoch 50/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.9761\n",
            "Epoch 00050: loss did not improve from 0.04080\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0521 - accuracy: 0.9762 - val_loss: 0.1363 - val_accuracy: 0.9522\n",
            "Epoch 51/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0915 - accuracy: 0.9636\n",
            "Epoch 00051: loss did not improve from 0.04080\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0914 - accuracy: 0.9636 - val_loss: 0.1336 - val_accuracy: 0.9486\n",
            "Epoch 52/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0562 - accuracy: 0.9744\n",
            "Epoch 00052: loss did not improve from 0.04080\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0562 - accuracy: 0.9744 - val_loss: 0.1570 - val_accuracy: 0.9410\n",
            "Epoch 53/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0461 - accuracy: 0.9783\n",
            "Epoch 00053: loss did not improve from 0.04080\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0463 - accuracy: 0.9782 - val_loss: 0.1243 - val_accuracy: 0.9534\n",
            "Epoch 54/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0426 - accuracy: 0.9795\n",
            "Epoch 00054: loss did not improve from 0.04080\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0425 - accuracy: 0.9795 - val_loss: 0.1301 - val_accuracy: 0.9542\n",
            "Epoch 55/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9814\n",
            "Epoch 00055: loss improved from 0.04080 to 0.03678, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 31ms/step - loss: 0.0368 - accuracy: 0.9814 - val_loss: 0.1328 - val_accuracy: 0.9551\n",
            "Epoch 56/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9819\n",
            "Epoch 00056: loss improved from 0.03678 to 0.03544, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0354 - accuracy: 0.9819 - val_loss: 0.1313 - val_accuracy: 0.9554\n",
            "Epoch 57/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0312 - accuracy: 0.9836\n",
            "Epoch 00057: loss improved from 0.03544 to 0.03152, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0315 - accuracy: 0.9834 - val_loss: 0.1322 - val_accuracy: 0.9563\n",
            "Epoch 58/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9827\n",
            "Epoch 00058: loss did not improve from 0.03152\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0325 - accuracy: 0.9829 - val_loss: 0.1289 - val_accuracy: 0.9570\n",
            "Epoch 59/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9834\n",
            "Epoch 00059: loss improved from 0.03152 to 0.03116, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0312 - accuracy: 0.9835 - val_loss: 0.1341 - val_accuracy: 0.9565\n",
            "Epoch 60/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0366 - accuracy: 0.9818\n",
            "Epoch 00060: loss did not improve from 0.03116\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0365 - accuracy: 0.9819 - val_loss: 0.1544 - val_accuracy: 0.9532\n",
            "Epoch 61/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9840\n",
            "Epoch 00061: loss improved from 0.03116 to 0.03025, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0303 - accuracy: 0.9839 - val_loss: 0.1403 - val_accuracy: 0.9583\n",
            "Epoch 62/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0287 - accuracy: 0.9843\n",
            "Epoch 00062: loss improved from 0.03025 to 0.02848, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0285 - accuracy: 0.9845 - val_loss: 0.1355 - val_accuracy: 0.9584\n",
            "Epoch 63/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9849\n",
            "Epoch 00063: loss improved from 0.02848 to 0.02726, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0273 - accuracy: 0.9849 - val_loss: 0.1388 - val_accuracy: 0.9576\n",
            "Epoch 64/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9851\n",
            "Epoch 00064: loss improved from 0.02726 to 0.02694, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0269 - accuracy: 0.9851 - val_loss: 0.1566 - val_accuracy: 0.9539\n",
            "Epoch 65/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9852\n",
            "Epoch 00065: loss improved from 0.02694 to 0.02677, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0268 - accuracy: 0.9852 - val_loss: 0.1344 - val_accuracy: 0.9563\n",
            "Epoch 66/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9849\n",
            "Epoch 00066: loss did not improve from 0.02677\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0271 - accuracy: 0.9849 - val_loss: 0.1422 - val_accuracy: 0.9579\n",
            "Epoch 67/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0276 - accuracy: 0.9848\n",
            "Epoch 00067: loss did not improve from 0.02677\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0275 - accuracy: 0.9849 - val_loss: 0.1511 - val_accuracy: 0.9565\n",
            "Epoch 68/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0268 - accuracy: 0.9847\n",
            "Epoch 00068: loss did not improve from 0.02677\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0269 - accuracy: 0.9847 - val_loss: 0.1389 - val_accuracy: 0.9580\n",
            "Epoch 69/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9863\n",
            "Epoch 00069: loss improved from 0.02677 to 0.02356, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0236 - accuracy: 0.9862 - val_loss: 0.1468 - val_accuracy: 0.9568\n",
            "Epoch 70/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9869\n",
            "Epoch 00070: loss improved from 0.02356 to 0.02247, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0225 - accuracy: 0.9869 - val_loss: 0.1407 - val_accuracy: 0.9571\n",
            "Epoch 71/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9791\n",
            "Epoch 00071: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0450 - accuracy: 0.9789 - val_loss: 0.1486 - val_accuracy: 0.9477\n",
            "Epoch 72/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1733 - accuracy: 0.9384\n",
            "Epoch 00072: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.1730 - accuracy: 0.9385 - val_loss: 0.1714 - val_accuracy: 0.9376\n",
            "Epoch 73/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.1340 - accuracy: 0.9465\n",
            "Epoch 00073: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1327 - accuracy: 0.9471 - val_loss: 0.1648 - val_accuracy: 0.9349\n",
            "Epoch 74/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0727 - accuracy: 0.9693\n",
            "Epoch 00074: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0734 - accuracy: 0.9690 - val_loss: 0.1300 - val_accuracy: 0.9530\n",
            "Epoch 75/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0808 - accuracy: 0.9667\n",
            "Epoch 00075: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0801 - accuracy: 0.9670 - val_loss: 0.1495 - val_accuracy: 0.9491\n",
            "Epoch 76/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0973 - accuracy: 0.9617\n",
            "Epoch 00076: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0970 - accuracy: 0.9617 - val_loss: 0.1716 - val_accuracy: 0.9357\n",
            "Epoch 77/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.9699\n",
            "Epoch 00077: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0714 - accuracy: 0.9700 - val_loss: 0.1332 - val_accuracy: 0.9490\n",
            "Epoch 78/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0634 - accuracy: 0.9727\n",
            "Epoch 00078: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0633 - accuracy: 0.9727 - val_loss: 0.1467 - val_accuracy: 0.9499\n",
            "Epoch 79/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0471 - accuracy: 0.9778\n",
            "Epoch 00079: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0468 - accuracy: 0.9779 - val_loss: 0.1318 - val_accuracy: 0.9544\n",
            "Epoch 80/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0371 - accuracy: 0.9814\n",
            "Epoch 00080: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0368 - accuracy: 0.9815 - val_loss: 0.1336 - val_accuracy: 0.9555\n",
            "Epoch 81/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0297 - accuracy: 0.9841\n",
            "Epoch 00081: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0295 - accuracy: 0.9842 - val_loss: 0.1403 - val_accuracy: 0.9573\n",
            "Epoch 82/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9849\n",
            "Epoch 00082: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0278 - accuracy: 0.9849 - val_loss: 0.1491 - val_accuracy: 0.9563\n",
            "Epoch 83/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0239 - accuracy: 0.9863\n",
            "Epoch 00083: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0239 - accuracy: 0.9863 - val_loss: 0.1536 - val_accuracy: 0.9560\n",
            "Epoch 84/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9859\n",
            "Epoch 00084: loss did not improve from 0.02247\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0250 - accuracy: 0.9858 - val_loss: 0.1567 - val_accuracy: 0.9589\n",
            "Epoch 85/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9873\n",
            "Epoch 00085: loss improved from 0.02247 to 0.02149, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0215 - accuracy: 0.9873 - val_loss: 0.1525 - val_accuracy: 0.9581\n",
            "Epoch 86/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0206 - accuracy: 0.9877\n",
            "Epoch 00086: loss improved from 0.02149 to 0.02061, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 31ms/step - loss: 0.0206 - accuracy: 0.9877 - val_loss: 0.1588 - val_accuracy: 0.9568\n",
            "Epoch 87/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9875\n",
            "Epoch 00087: loss improved from 0.02061 to 0.02033, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0203 - accuracy: 0.9875 - val_loss: 0.1557 - val_accuracy: 0.9590\n",
            "Epoch 88/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9865\n",
            "Epoch 00088: loss did not improve from 0.02033\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0229 - accuracy: 0.9865 - val_loss: 0.1530 - val_accuracy: 0.9578\n",
            "Epoch 89/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9882\n",
            "Epoch 00089: loss improved from 0.02033 to 0.01910, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0191 - accuracy: 0.9882 - val_loss: 0.1553 - val_accuracy: 0.9567\n",
            "Epoch 90/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9870\n",
            "Epoch 00090: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0212 - accuracy: 0.9870 - val_loss: 0.1583 - val_accuracy: 0.9576\n",
            "Epoch 91/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.9864\n",
            "Epoch 00091: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0237 - accuracy: 0.9863 - val_loss: 0.1664 - val_accuracy: 0.9576\n",
            "Epoch 92/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9867\n",
            "Epoch 00092: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0221 - accuracy: 0.9867 - val_loss: 0.1709 - val_accuracy: 0.9509\n",
            "Epoch 93/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9854\n",
            "Epoch 00093: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0252 - accuracy: 0.9855 - val_loss: 0.1615 - val_accuracy: 0.9575\n",
            "Epoch 94/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9866\n",
            "Epoch 00094: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0231 - accuracy: 0.9867 - val_loss: 0.1488 - val_accuracy: 0.9573\n",
            "Epoch 95/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9871\n",
            "Epoch 00095: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0217 - accuracy: 0.9871 - val_loss: 0.1523 - val_accuracy: 0.9579\n",
            "Epoch 96/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.9866\n",
            "Epoch 00096: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0227 - accuracy: 0.9866 - val_loss: 0.1571 - val_accuracy: 0.9565\n",
            "Epoch 97/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9867\n",
            "Epoch 00097: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0224 - accuracy: 0.9868 - val_loss: 0.1490 - val_accuracy: 0.9584\n",
            "Epoch 98/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9879\n",
            "Epoch 00098: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0195 - accuracy: 0.9879 - val_loss: 0.1499 - val_accuracy: 0.9590\n",
            "Epoch 99/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0211 - accuracy: 0.9874\n",
            "Epoch 00099: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0213 - accuracy: 0.9873 - val_loss: 0.1645 - val_accuracy: 0.9593\n",
            "Epoch 100/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9876\n",
            "Epoch 00100: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0200 - accuracy: 0.9876 - val_loss: 0.1511 - val_accuracy: 0.9600\n",
            "Epoch 101/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9868\n",
            "Epoch 00101: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0221 - accuracy: 0.9869 - val_loss: 0.1622 - val_accuracy: 0.9575\n",
            "Epoch 102/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 0.9844\n",
            "Epoch 00102: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0292 - accuracy: 0.9845 - val_loss: 0.1544 - val_accuracy: 0.9530\n",
            "Epoch 103/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9797\n",
            "Epoch 00103: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0432 - accuracy: 0.9798 - val_loss: 0.1621 - val_accuracy: 0.9482\n",
            "Epoch 104/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0433 - accuracy: 0.9800\n",
            "Epoch 00104: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0433 - accuracy: 0.9799 - val_loss: 0.1591 - val_accuracy: 0.9445\n",
            "Epoch 105/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0956 - accuracy: 0.9637\n",
            "Epoch 00105: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0949 - accuracy: 0.9641 - val_loss: 0.1582 - val_accuracy: 0.9454\n",
            "Epoch 106/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.1177 - accuracy: 0.9565\n",
            "Epoch 00106: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.1164 - accuracy: 0.9568 - val_loss: 0.1409 - val_accuracy: 0.9484\n",
            "Epoch 107/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9724\n",
            "Epoch 00107: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0686 - accuracy: 0.9721 - val_loss: 0.1343 - val_accuracy: 0.9547\n",
            "Epoch 108/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0543 - accuracy: 0.9764\n",
            "Epoch 00108: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0546 - accuracy: 0.9763 - val_loss: 0.1318 - val_accuracy: 0.9563\n",
            "Epoch 109/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0393 - accuracy: 0.9810\n",
            "Epoch 00109: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0390 - accuracy: 0.9811 - val_loss: 0.1308 - val_accuracy: 0.9582\n",
            "Epoch 110/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9845\n",
            "Epoch 00110: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0292 - accuracy: 0.9845 - val_loss: 0.1260 - val_accuracy: 0.9606\n",
            "Epoch 111/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9867\n",
            "Epoch 00111: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0230 - accuracy: 0.9867 - val_loss: 0.1287 - val_accuracy: 0.9624\n",
            "Epoch 112/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0220 - accuracy: 0.9868\n",
            "Epoch 00112: loss did not improve from 0.01910\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0221 - accuracy: 0.9868 - val_loss: 0.1342 - val_accuracy: 0.9614\n",
            "Epoch 113/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9886\n",
            "Epoch 00113: loss improved from 0.01910 to 0.01741, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0174 - accuracy: 0.9887 - val_loss: 0.1393 - val_accuracy: 0.9622\n",
            "Epoch 114/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9885\n",
            "Epoch 00114: loss improved from 0.01741 to 0.01716, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0172 - accuracy: 0.9885 - val_loss: 0.1400 - val_accuracy: 0.9626\n",
            "Epoch 115/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9893\n",
            "Epoch 00115: loss improved from 0.01716 to 0.01601, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0160 - accuracy: 0.9892 - val_loss: 0.1408 - val_accuracy: 0.9630\n",
            "Epoch 116/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9888\n",
            "Epoch 00116: loss did not improve from 0.01601\n",
            "114/114 [==============================] - 3s 31ms/step - loss: 0.0165 - accuracy: 0.9888 - val_loss: 0.1458 - val_accuracy: 0.9626\n",
            "Epoch 117/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9888\n",
            "Epoch 00117: loss did not improve from 0.01601\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0164 - accuracy: 0.9888 - val_loss: 0.1525 - val_accuracy: 0.9629\n",
            "Epoch 118/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9886\n",
            "Epoch 00118: loss did not improve from 0.01601\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0177 - accuracy: 0.9885 - val_loss: 0.1436 - val_accuracy: 0.9625\n",
            "Epoch 119/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9891\n",
            "Epoch 00119: loss improved from 0.01601 to 0.01570, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0157 - accuracy: 0.9891 - val_loss: 0.1534 - val_accuracy: 0.9621\n",
            "Epoch 120/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9895\n",
            "Epoch 00120: loss improved from 0.01570 to 0.01462, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0146 - accuracy: 0.9895 - val_loss: 0.1528 - val_accuracy: 0.9638\n",
            "Epoch 121/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9891\n",
            "Epoch 00121: loss did not improve from 0.01462\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0161 - accuracy: 0.9890 - val_loss: 0.1519 - val_accuracy: 0.9633\n",
            "Epoch 122/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9889\n",
            "Epoch 00122: loss did not improve from 0.01462\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0161 - accuracy: 0.9890 - val_loss: 0.1592 - val_accuracy: 0.9631\n",
            "Epoch 123/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9896\n",
            "Epoch 00123: loss improved from 0.01462 to 0.01450, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0145 - accuracy: 0.9897 - val_loss: 0.1615 - val_accuracy: 0.9619\n",
            "Epoch 124/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9897\n",
            "Epoch 00124: loss improved from 0.01450 to 0.01445, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0145 - accuracy: 0.9897 - val_loss: 0.1477 - val_accuracy: 0.9623\n",
            "Epoch 125/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9895\n",
            "Epoch 00125: loss improved from 0.01445 to 0.01443, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0144 - accuracy: 0.9895 - val_loss: 0.1626 - val_accuracy: 0.9621\n",
            "Epoch 126/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9902\n",
            "Epoch 00126: loss improved from 0.01443 to 0.01311, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0131 - accuracy: 0.9902 - val_loss: 0.1749 - val_accuracy: 0.9614\n",
            "Epoch 127/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9897\n",
            "Epoch 00127: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0147 - accuracy: 0.9897 - val_loss: 0.1587 - val_accuracy: 0.9630\n",
            "Epoch 128/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9889\n",
            "Epoch 00128: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0160 - accuracy: 0.9890 - val_loss: 0.1609 - val_accuracy: 0.9613\n",
            "Epoch 129/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9895\n",
            "Epoch 00129: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0150 - accuracy: 0.9895 - val_loss: 0.1695 - val_accuracy: 0.9612\n",
            "Epoch 130/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0215 - accuracy: 0.9872\n",
            "Epoch 00130: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0222 - accuracy: 0.9869 - val_loss: 0.1937 - val_accuracy: 0.9551\n",
            "Epoch 131/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.1895 - accuracy: 0.9375\n",
            "Epoch 00131: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1886 - accuracy: 0.9375 - val_loss: 0.2218 - val_accuracy: 0.9272\n",
            "Epoch 132/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1060 - accuracy: 0.9597\n",
            "Epoch 00132: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.1057 - accuracy: 0.9598 - val_loss: 0.1619 - val_accuracy: 0.9397\n",
            "Epoch 133/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0746 - accuracy: 0.9709\n",
            "Epoch 00133: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0754 - accuracy: 0.9706 - val_loss: 0.1397 - val_accuracy: 0.9520\n",
            "Epoch 134/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0665 - accuracy: 0.9729\n",
            "Epoch 00134: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0662 - accuracy: 0.9730 - val_loss: 0.1335 - val_accuracy: 0.9531\n",
            "Epoch 135/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0588 - accuracy: 0.9747\n",
            "Epoch 00135: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0585 - accuracy: 0.9748 - val_loss: 0.1203 - val_accuracy: 0.9567\n",
            "Epoch 136/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0299 - accuracy: 0.9846\n",
            "Epoch 00136: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 31ms/step - loss: 0.0297 - accuracy: 0.9847 - val_loss: 0.1292 - val_accuracy: 0.9605\n",
            "Epoch 137/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0249 - accuracy: 0.9859\n",
            "Epoch 00137: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0251 - accuracy: 0.9859 - val_loss: 0.1384 - val_accuracy: 0.9619\n",
            "Epoch 138/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0209 - accuracy: 0.9874\n",
            "Epoch 00138: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0210 - accuracy: 0.9873 - val_loss: 0.1398 - val_accuracy: 0.9624\n",
            "Epoch 139/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9873\n",
            "Epoch 00139: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0214 - accuracy: 0.9874 - val_loss: 0.1335 - val_accuracy: 0.9612\n",
            "Epoch 140/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9879\n",
            "Epoch 00140: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0196 - accuracy: 0.9879 - val_loss: 0.1349 - val_accuracy: 0.9616\n",
            "Epoch 141/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9872\n",
            "Epoch 00141: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0227 - accuracy: 0.9873 - val_loss: 0.1396 - val_accuracy: 0.9620\n",
            "Epoch 142/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9885\n",
            "Epoch 00142: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0174 - accuracy: 0.9886 - val_loss: 0.1502 - val_accuracy: 0.9621\n",
            "Epoch 143/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9886\n",
            "Epoch 00143: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0164 - accuracy: 0.9887 - val_loss: 0.1549 - val_accuracy: 0.9619\n",
            "Epoch 144/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9896\n",
            "Epoch 00144: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0150 - accuracy: 0.9895 - val_loss: 0.1535 - val_accuracy: 0.9623\n",
            "Epoch 145/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9892\n",
            "Epoch 00145: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0157 - accuracy: 0.9893 - val_loss: 0.1548 - val_accuracy: 0.9634\n",
            "Epoch 146/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9896\n",
            "Epoch 00146: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0141 - accuracy: 0.9897 - val_loss: 0.1583 - val_accuracy: 0.9630\n",
            "Epoch 147/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9894\n",
            "Epoch 00147: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0146 - accuracy: 0.9894 - val_loss: 0.1684 - val_accuracy: 0.9623\n",
            "Epoch 148/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9900\n",
            "Epoch 00148: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0134 - accuracy: 0.9900 - val_loss: 0.1819 - val_accuracy: 0.9622\n",
            "Epoch 149/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9898\n",
            "Epoch 00149: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0139 - accuracy: 0.9897 - val_loss: 0.1727 - val_accuracy: 0.9614\n",
            "Epoch 150/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9896\n",
            "Epoch 00150: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 31ms/step - loss: 0.0151 - accuracy: 0.9895 - val_loss: 0.1690 - val_accuracy: 0.9588\n",
            "Epoch 151/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9852\n",
            "Epoch 00151: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0270 - accuracy: 0.9852 - val_loss: 0.1504 - val_accuracy: 0.9559\n",
            "Epoch 152/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9853\n",
            "Epoch 00152: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0268 - accuracy: 0.9855 - val_loss: 0.1358 - val_accuracy: 0.9578\n",
            "Epoch 153/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9849\n",
            "Epoch 00153: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0284 - accuracy: 0.9849 - val_loss: 0.1319 - val_accuracy: 0.9579\n",
            "Epoch 154/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9796\n",
            "Epoch 00154: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0437 - accuracy: 0.9799 - val_loss: 0.1331 - val_accuracy: 0.9588\n",
            "Epoch 155/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 0.9757\n",
            "Epoch 00155: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0631 - accuracy: 0.9756 - val_loss: 0.1602 - val_accuracy: 0.9401\n",
            "Epoch 156/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0723 - accuracy: 0.9700\n",
            "Epoch 00156: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0717 - accuracy: 0.9702 - val_loss: 0.1464 - val_accuracy: 0.9519\n",
            "Epoch 157/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9831\n",
            "Epoch 00157: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0339 - accuracy: 0.9831 - val_loss: 0.1392 - val_accuracy: 0.9581\n",
            "Epoch 158/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9868\n",
            "Epoch 00158: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0227 - accuracy: 0.9867 - val_loss: 0.1542 - val_accuracy: 0.9586\n",
            "Epoch 159/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9879\n",
            "Epoch 00159: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0203 - accuracy: 0.9878 - val_loss: 0.1665 - val_accuracy: 0.9584\n",
            "Epoch 160/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9881\n",
            "Epoch 00160: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0191 - accuracy: 0.9881 - val_loss: 0.1666 - val_accuracy: 0.9584\n",
            "Epoch 161/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9886\n",
            "Epoch 00161: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0177 - accuracy: 0.9886 - val_loss: 0.1625 - val_accuracy: 0.9597\n",
            "Epoch 162/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9888\n",
            "Epoch 00162: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0169 - accuracy: 0.9888 - val_loss: 0.1493 - val_accuracy: 0.9605\n",
            "Epoch 163/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9893\n",
            "Epoch 00163: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0154 - accuracy: 0.9892 - val_loss: 0.1666 - val_accuracy: 0.9618\n",
            "Epoch 164/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9894\n",
            "Epoch 00164: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0151 - accuracy: 0.9894 - val_loss: 0.1684 - val_accuracy: 0.9612\n",
            "Epoch 165/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9902\n",
            "Epoch 00165: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0132 - accuracy: 0.9902 - val_loss: 0.1660 - val_accuracy: 0.9612\n",
            "Epoch 166/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9898\n",
            "Epoch 00166: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0139 - accuracy: 0.9898 - val_loss: 0.1713 - val_accuracy: 0.9617\n",
            "Epoch 167/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9898\n",
            "Epoch 00167: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0139 - accuracy: 0.9898 - val_loss: 0.1694 - val_accuracy: 0.9613\n",
            "Epoch 168/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9895\n",
            "Epoch 00168: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0143 - accuracy: 0.9896 - val_loss: 0.1926 - val_accuracy: 0.9602\n",
            "Epoch 169/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9896\n",
            "Epoch 00169: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0147 - accuracy: 0.9896 - val_loss: 0.1740 - val_accuracy: 0.9607\n",
            "Epoch 170/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9901\n",
            "Epoch 00170: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0133 - accuracy: 0.9902 - val_loss: 0.1752 - val_accuracy: 0.9616\n",
            "Epoch 171/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9898\n",
            "Epoch 00171: loss did not improve from 0.01311\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0134 - accuracy: 0.9898 - val_loss: 0.1639 - val_accuracy: 0.9616\n",
            "Epoch 172/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9902\n",
            "Epoch 00172: loss improved from 0.01311 to 0.01281, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0128 - accuracy: 0.9902 - val_loss: 0.1666 - val_accuracy: 0.9619\n",
            "Epoch 173/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0550 - accuracy: 0.9774\n",
            "Epoch 00173: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0549 - accuracy: 0.9774 - val_loss: 0.1479 - val_accuracy: 0.9454\n",
            "Epoch 174/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1221 - accuracy: 0.9560\n",
            "Epoch 00174: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.1219 - accuracy: 0.9561 - val_loss: 0.1510 - val_accuracy: 0.9487\n",
            "Epoch 175/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1038 - accuracy: 0.9659\n",
            "Epoch 00175: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.1034 - accuracy: 0.9659 - val_loss: 0.1427 - val_accuracy: 0.9467\n",
            "Epoch 176/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.9566\n",
            "Epoch 00176: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.1126 - accuracy: 0.9568 - val_loss: 0.1294 - val_accuracy: 0.9548\n",
            "Epoch 177/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 0.9758\n",
            "Epoch 00177: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0573 - accuracy: 0.9757 - val_loss: 0.1385 - val_accuracy: 0.9542\n",
            "Epoch 178/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0536 - accuracy: 0.9782\n",
            "Epoch 00178: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0536 - accuracy: 0.9782 - val_loss: 0.1406 - val_accuracy: 0.9573\n",
            "Epoch 179/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0405 - accuracy: 0.9819\n",
            "Epoch 00179: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0403 - accuracy: 0.9819 - val_loss: 0.1436 - val_accuracy: 0.9582\n",
            "Epoch 180/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.9843\n",
            "Epoch 00180: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 34ms/step - loss: 0.0307 - accuracy: 0.9842 - val_loss: 0.1647 - val_accuracy: 0.9553\n",
            "Epoch 181/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9858\n",
            "Epoch 00181: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0255 - accuracy: 0.9858 - val_loss: 0.1480 - val_accuracy: 0.9601\n",
            "Epoch 182/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9873\n",
            "Epoch 00182: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0216 - accuracy: 0.9873 - val_loss: 0.1406 - val_accuracy: 0.9618\n",
            "Epoch 183/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9870\n",
            "Epoch 00183: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0212 - accuracy: 0.9871 - val_loss: 0.1541 - val_accuracy: 0.9603\n",
            "Epoch 184/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9887\n",
            "Epoch 00184: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0171 - accuracy: 0.9888 - val_loss: 0.1661 - val_accuracy: 0.9610\n",
            "Epoch 185/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9891\n",
            "Epoch 00185: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0164 - accuracy: 0.9890 - val_loss: 0.1557 - val_accuracy: 0.9616\n",
            "Epoch 186/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9891\n",
            "Epoch 00186: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0156 - accuracy: 0.9891 - val_loss: 0.1831 - val_accuracy: 0.9598\n",
            "Epoch 187/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9893\n",
            "Epoch 00187: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0155 - accuracy: 0.9893 - val_loss: 0.1624 - val_accuracy: 0.9626\n",
            "Epoch 188/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9897\n",
            "Epoch 00188: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0147 - accuracy: 0.9897 - val_loss: 0.1641 - val_accuracy: 0.9619\n",
            "Epoch 189/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9897\n",
            "Epoch 00189: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0142 - accuracy: 0.9897 - val_loss: 0.1596 - val_accuracy: 0.9629\n",
            "Epoch 190/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9899\n",
            "Epoch 00190: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0138 - accuracy: 0.9898 - val_loss: 0.1715 - val_accuracy: 0.9621\n",
            "Epoch 191/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9899\n",
            "Epoch 00191: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0136 - accuracy: 0.9899 - val_loss: 0.1656 - val_accuracy: 0.9623\n",
            "Epoch 192/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9902\n",
            "Epoch 00192: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0130 - accuracy: 0.9902 - val_loss: 0.1748 - val_accuracy: 0.9619\n",
            "Epoch 193/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9900\n",
            "Epoch 00193: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0132 - accuracy: 0.9900 - val_loss: 0.1798 - val_accuracy: 0.9610\n",
            "Epoch 194/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9901\n",
            "Epoch 00194: loss did not improve from 0.01281\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0130 - accuracy: 0.9900 - val_loss: 0.1748 - val_accuracy: 0.9617\n",
            "Epoch 195/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9908\n",
            "Epoch 00195: loss improved from 0.01281 to 0.01188, saving model to unet_tem.hdf5\n",
            "114/114 [==============================] - 4s 33ms/step - loss: 0.0119 - accuracy: 0.9907 - val_loss: 0.1811 - val_accuracy: 0.9615\n",
            "Epoch 196/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9904\n",
            "Epoch 00196: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0123 - accuracy: 0.9904 - val_loss: 0.1814 - val_accuracy: 0.9619\n",
            "Epoch 197/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9903\n",
            "Epoch 00197: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0125 - accuracy: 0.9903 - val_loss: 0.1826 - val_accuracy: 0.9623\n",
            "Epoch 198/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9905\n",
            "Epoch 00198: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0124 - accuracy: 0.9905 - val_loss: 0.1739 - val_accuracy: 0.9639\n",
            "Epoch 199/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9899\n",
            "Epoch 00199: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0134 - accuracy: 0.9900 - val_loss: 0.1707 - val_accuracy: 0.9633\n",
            "Epoch 200/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9899\n",
            "Epoch 00200: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0139 - accuracy: 0.9899 - val_loss: 0.1761 - val_accuracy: 0.9636\n",
            "Epoch 201/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0529 - accuracy: 0.9776\n",
            "Epoch 00201: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 31ms/step - loss: 0.0536 - accuracy: 0.9774 - val_loss: 0.2021 - val_accuracy: 0.9407\n",
            "Epoch 202/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.1201 - accuracy: 0.9547\n",
            "Epoch 00202: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.1223 - accuracy: 0.9542 - val_loss: 0.1489 - val_accuracy: 0.9477\n",
            "Epoch 203/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0525 - accuracy: 0.9772\n",
            "Epoch 00203: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 33ms/step - loss: 0.0524 - accuracy: 0.9773 - val_loss: 0.1281 - val_accuracy: 0.9588\n",
            "Epoch 204/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9823\n",
            "Epoch 00204: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0353 - accuracy: 0.9824 - val_loss: 0.1323 - val_accuracy: 0.9627\n",
            "Epoch 205/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0408 - accuracy: 0.9804\n",
            "Epoch 00205: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0408 - accuracy: 0.9803 - val_loss: 0.1344 - val_accuracy: 0.9602\n",
            "Epoch 206/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9861\n",
            "Epoch 00206: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 33ms/step - loss: 0.0252 - accuracy: 0.9861 - val_loss: 0.1305 - val_accuracy: 0.9622\n",
            "Epoch 207/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9868\n",
            "Epoch 00207: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0241 - accuracy: 0.9868 - val_loss: 0.1385 - val_accuracy: 0.9619\n",
            "Epoch 208/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0384 - accuracy: 0.9819\n",
            "Epoch 00208: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0385 - accuracy: 0.9819 - val_loss: 0.1437 - val_accuracy: 0.9596\n",
            "Epoch 209/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9845\n",
            "Epoch 00209: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 31ms/step - loss: 0.0309 - accuracy: 0.9844 - val_loss: 0.1550 - val_accuracy: 0.9591\n",
            "Epoch 210/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9847\n",
            "Epoch 00210: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0285 - accuracy: 0.9847 - val_loss: 0.1321 - val_accuracy: 0.9634\n",
            "Epoch 211/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9872\n",
            "Epoch 00211: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0216 - accuracy: 0.9871 - val_loss: 0.1420 - val_accuracy: 0.9629\n",
            "Epoch 212/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9877\n",
            "Epoch 00212: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0198 - accuracy: 0.9876 - val_loss: 0.1368 - val_accuracy: 0.9645\n",
            "Epoch 213/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9893\n",
            "Epoch 00213: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0159 - accuracy: 0.9892 - val_loss: 0.1434 - val_accuracy: 0.9648\n",
            "Epoch 214/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9899\n",
            "Epoch 00214: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0141 - accuracy: 0.9899 - val_loss: 0.1473 - val_accuracy: 0.9649\n",
            "Epoch 215/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9896\n",
            "Epoch 00215: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0147 - accuracy: 0.9895 - val_loss: 0.1544 - val_accuracy: 0.9644\n",
            "Epoch 216/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9893\n",
            "Epoch 00216: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0154 - accuracy: 0.9893 - val_loss: 0.1506 - val_accuracy: 0.9638\n",
            "Epoch 217/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9896\n",
            "Epoch 00217: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0144 - accuracy: 0.9896 - val_loss: 0.1508 - val_accuracy: 0.9643\n",
            "Epoch 218/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9900\n",
            "Epoch 00218: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0132 - accuracy: 0.9901 - val_loss: 0.1709 - val_accuracy: 0.9630\n",
            "Epoch 219/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9898\n",
            "Epoch 00219: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0136 - accuracy: 0.9898 - val_loss: 0.1594 - val_accuracy: 0.9643\n",
            "Epoch 220/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9902\n",
            "Epoch 00220: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0133 - accuracy: 0.9901 - val_loss: 0.1662 - val_accuracy: 0.9649\n",
            "Epoch 221/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9901\n",
            "Epoch 00221: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0128 - accuracy: 0.9902 - val_loss: 0.1695 - val_accuracy: 0.9641\n",
            "Epoch 222/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9903\n",
            "Epoch 00222: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0126 - accuracy: 0.9903 - val_loss: 0.1660 - val_accuracy: 0.9639\n",
            "Epoch 223/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9906\n",
            "Epoch 00223: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0122 - accuracy: 0.9906 - val_loss: 0.1720 - val_accuracy: 0.9642\n",
            "Epoch 224/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9904\n",
            "Epoch 00224: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0125 - accuracy: 0.9904 - val_loss: 0.1718 - val_accuracy: 0.9631\n",
            "Epoch 225/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9900\n",
            "Epoch 00225: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0139 - accuracy: 0.9899 - val_loss: 0.1866 - val_accuracy: 0.9616\n",
            "Epoch 226/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9896\n",
            "Epoch 00226: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0146 - accuracy: 0.9896 - val_loss: 0.1598 - val_accuracy: 0.9619\n",
            "Epoch 227/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0210 - accuracy: 0.9875\n",
            "Epoch 00227: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0217 - accuracy: 0.9874 - val_loss: 0.1520 - val_accuracy: 0.9588\n",
            "Epoch 228/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0650 - accuracy: 0.9738\n",
            "Epoch 00228: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 31ms/step - loss: 0.0644 - accuracy: 0.9739 - val_loss: 0.1411 - val_accuracy: 0.9490\n",
            "Epoch 229/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.1078 - accuracy: 0.9629\n",
            "Epoch 00229: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.1072 - accuracy: 0.9630 - val_loss: 0.1530 - val_accuracy: 0.9460\n",
            "Epoch 230/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0645 - accuracy: 0.9737\n",
            "Epoch 00230: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 32ms/step - loss: 0.0645 - accuracy: 0.9737 - val_loss: 0.1574 - val_accuracy: 0.9550\n",
            "Epoch 231/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0321 - accuracy: 0.9839\n",
            "Epoch 00231: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0318 - accuracy: 0.9840 - val_loss: 0.1310 - val_accuracy: 0.9596\n",
            "Epoch 232/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0226 - accuracy: 0.9870\n",
            "Epoch 00232: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0225 - accuracy: 0.9871 - val_loss: 0.1504 - val_accuracy: 0.9600\n",
            "Epoch 233/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9874\n",
            "Epoch 00233: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0206 - accuracy: 0.9875 - val_loss: 0.1496 - val_accuracy: 0.9608\n",
            "Epoch 234/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9865\n",
            "Epoch 00234: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 31ms/step - loss: 0.0246 - accuracy: 0.9865 - val_loss: 0.1387 - val_accuracy: 0.9611\n",
            "Epoch 235/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9885\n",
            "Epoch 00235: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 31ms/step - loss: 0.0178 - accuracy: 0.9884 - val_loss: 0.1527 - val_accuracy: 0.9624\n",
            "Epoch 236/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9893\n",
            "Epoch 00236: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0160 - accuracy: 0.9893 - val_loss: 0.1440 - val_accuracy: 0.9624\n",
            "Epoch 237/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9895\n",
            "Epoch 00237: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0153 - accuracy: 0.9895 - val_loss: 0.1540 - val_accuracy: 0.9623\n",
            "Epoch 238/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9893\n",
            "Epoch 00238: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0149 - accuracy: 0.9893 - val_loss: 0.1620 - val_accuracy: 0.9630\n",
            "Epoch 239/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9897\n",
            "Epoch 00239: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0156 - accuracy: 0.9896 - val_loss: 0.1545 - val_accuracy: 0.9605\n",
            "Epoch 240/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9899\n",
            "Epoch 00240: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0140 - accuracy: 0.9899 - val_loss: 0.1613 - val_accuracy: 0.9631\n",
            "Epoch 241/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9899\n",
            "Epoch 00241: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0141 - accuracy: 0.9900 - val_loss: 0.1558 - val_accuracy: 0.9620\n",
            "Epoch 242/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0146 - accuracy: 0.9895\n",
            "Epoch 00242: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0145 - accuracy: 0.9895 - val_loss: 0.1692 - val_accuracy: 0.9641\n",
            "Epoch 243/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9901\n",
            "Epoch 00243: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0137 - accuracy: 0.9900 - val_loss: 0.1712 - val_accuracy: 0.9645\n",
            "Epoch 244/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9904\n",
            "Epoch 00244: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0128 - accuracy: 0.9904 - val_loss: 0.1740 - val_accuracy: 0.9612\n",
            "Epoch 245/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0429 - accuracy: 0.9807\n",
            "Epoch 00245: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0425 - accuracy: 0.9808 - val_loss: 0.1376 - val_accuracy: 0.9576\n",
            "Epoch 246/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9798\n",
            "Epoch 00246: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0466 - accuracy: 0.9796 - val_loss: 0.1369 - val_accuracy: 0.9588\n",
            "Epoch 247/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9701\n",
            "Epoch 00247: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0837 - accuracy: 0.9703 - val_loss: 0.1334 - val_accuracy: 0.9593\n",
            "Epoch 248/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.9791\n",
            "Epoch 00248: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0496 - accuracy: 0.9792 - val_loss: 0.1211 - val_accuracy: 0.9588\n",
            "Epoch 249/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9855\n",
            "Epoch 00249: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0279 - accuracy: 0.9854 - val_loss: 0.1358 - val_accuracy: 0.9620\n",
            "Epoch 250/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0245 - accuracy: 0.9863\n",
            "Epoch 00250: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0245 - accuracy: 0.9863 - val_loss: 0.1438 - val_accuracy: 0.9610\n",
            "Epoch 251/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0229 - accuracy: 0.9872\n",
            "Epoch 00251: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0228 - accuracy: 0.9872 - val_loss: 0.1648 - val_accuracy: 0.9598\n",
            "Epoch 252/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9883\n",
            "Epoch 00252: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0189 - accuracy: 0.9884 - val_loss: 0.1530 - val_accuracy: 0.9612\n",
            "Epoch 253/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9887\n",
            "Epoch 00253: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0180 - accuracy: 0.9887 - val_loss: 0.1582 - val_accuracy: 0.9614\n",
            "Epoch 254/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9890\n",
            "Epoch 00254: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0168 - accuracy: 0.9890 - val_loss: 0.1727 - val_accuracy: 0.9595\n",
            "Epoch 255/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9887\n",
            "Epoch 00255: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0172 - accuracy: 0.9887 - val_loss: 0.1490 - val_accuracy: 0.9622\n",
            "Epoch 256/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9894\n",
            "Epoch 00256: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0156 - accuracy: 0.9894 - val_loss: 0.1563 - val_accuracy: 0.9625\n",
            "Epoch 257/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9894\n",
            "Epoch 00257: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0148 - accuracy: 0.9894 - val_loss: 0.1596 - val_accuracy: 0.9633\n",
            "Epoch 258/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9892\n",
            "Epoch 00258: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0152 - accuracy: 0.9892 - val_loss: 0.1475 - val_accuracy: 0.9624\n",
            "Epoch 259/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9900\n",
            "Epoch 00259: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0132 - accuracy: 0.9900 - val_loss: 0.1698 - val_accuracy: 0.9624\n",
            "Epoch 260/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9900\n",
            "Epoch 00260: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0134 - accuracy: 0.9900 - val_loss: 0.1708 - val_accuracy: 0.9629\n",
            "Epoch 261/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9898\n",
            "Epoch 00261: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0148 - accuracy: 0.9898 - val_loss: 0.1639 - val_accuracy: 0.9641\n",
            "Epoch 262/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9901\n",
            "Epoch 00262: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0132 - accuracy: 0.9901 - val_loss: 0.1675 - val_accuracy: 0.9641\n",
            "Epoch 263/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9895\n",
            "Epoch 00263: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0144 - accuracy: 0.9895 - val_loss: 0.1590 - val_accuracy: 0.9642\n",
            "Epoch 264/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0213 - accuracy: 0.9874\n",
            "Epoch 00264: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0214 - accuracy: 0.9874 - val_loss: 0.1666 - val_accuracy: 0.9545\n",
            "Epoch 265/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9879\n",
            "Epoch 00265: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0194 - accuracy: 0.9879 - val_loss: 0.1640 - val_accuracy: 0.9592\n",
            "Epoch 266/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0300 - accuracy: 0.9847\n",
            "Epoch 00266: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0295 - accuracy: 0.9849 - val_loss: 0.1693 - val_accuracy: 0.9511\n",
            "Epoch 267/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0283 - accuracy: 0.9856\n",
            "Epoch 00267: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 31ms/step - loss: 0.0287 - accuracy: 0.9854 - val_loss: 0.1708 - val_accuracy: 0.9544\n",
            "Epoch 268/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0519 - accuracy: 0.9798\n",
            "Epoch 00268: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0517 - accuracy: 0.9799 - val_loss: 0.1383 - val_accuracy: 0.9522\n",
            "Epoch 269/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0435 - accuracy: 0.9800\n",
            "Epoch 00269: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0432 - accuracy: 0.9802 - val_loss: 0.1203 - val_accuracy: 0.9605\n",
            "Epoch 270/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0329 - accuracy: 0.9836\n",
            "Epoch 00270: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0328 - accuracy: 0.9837 - val_loss: 0.1400 - val_accuracy: 0.9597\n",
            "Epoch 271/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9881\n",
            "Epoch 00271: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0198 - accuracy: 0.9881 - val_loss: 0.1464 - val_accuracy: 0.9613\n",
            "Epoch 272/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9885\n",
            "Epoch 00272: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0180 - accuracy: 0.9884 - val_loss: 0.1525 - val_accuracy: 0.9628\n",
            "Epoch 273/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9882\n",
            "Epoch 00273: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0186 - accuracy: 0.9882 - val_loss: 0.1447 - val_accuracy: 0.9638\n",
            "Epoch 274/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9885\n",
            "Epoch 00274: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0178 - accuracy: 0.9885 - val_loss: 0.1517 - val_accuracy: 0.9639\n",
            "Epoch 275/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9787\n",
            "Epoch 00275: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0501 - accuracy: 0.9786 - val_loss: 0.1604 - val_accuracy: 0.9533\n",
            "Epoch 276/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0274 - accuracy: 0.9856\n",
            "Epoch 00276: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0272 - accuracy: 0.9857 - val_loss: 0.1434 - val_accuracy: 0.9604\n",
            "Epoch 277/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9882\n",
            "Epoch 00277: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0192 - accuracy: 0.9882 - val_loss: 0.1621 - val_accuracy: 0.9601\n",
            "Epoch 278/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9883\n",
            "Epoch 00278: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0194 - accuracy: 0.9880 - val_loss: 0.1407 - val_accuracy: 0.9602\n",
            "Epoch 279/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9840\n",
            "Epoch 00279: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0316 - accuracy: 0.9841 - val_loss: 0.1469 - val_accuracy: 0.9609\n",
            "Epoch 280/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0243 - accuracy: 0.9864\n",
            "Epoch 00280: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0243 - accuracy: 0.9864 - val_loss: 0.1330 - val_accuracy: 0.9568\n",
            "Epoch 281/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0293 - accuracy: 0.9856\n",
            "Epoch 00281: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0292 - accuracy: 0.9857 - val_loss: 0.1488 - val_accuracy: 0.9581\n",
            "Epoch 282/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0354 - accuracy: 0.9831\n",
            "Epoch 00282: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0351 - accuracy: 0.9832 - val_loss: 0.1410 - val_accuracy: 0.9614\n",
            "Epoch 283/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9877\n",
            "Epoch 00283: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0201 - accuracy: 0.9878 - val_loss: 0.1441 - val_accuracy: 0.9635\n",
            "Epoch 284/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9888\n",
            "Epoch 00284: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0165 - accuracy: 0.9888 - val_loss: 0.1533 - val_accuracy: 0.9618\n",
            "Epoch 285/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9887\n",
            "Epoch 00285: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0172 - accuracy: 0.9888 - val_loss: 0.1472 - val_accuracy: 0.9634\n",
            "Epoch 286/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9897\n",
            "Epoch 00286: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0142 - accuracy: 0.9898 - val_loss: 0.1521 - val_accuracy: 0.9634\n",
            "Epoch 287/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9895\n",
            "Epoch 00287: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0146 - accuracy: 0.9895 - val_loss: 0.1639 - val_accuracy: 0.9620\n",
            "Epoch 288/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0188 - accuracy: 0.9885\n",
            "Epoch 00288: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0192 - accuracy: 0.9883 - val_loss: 0.1526 - val_accuracy: 0.9621\n",
            "Epoch 289/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9894\n",
            "Epoch 00289: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0159 - accuracy: 0.9894 - val_loss: 0.1649 - val_accuracy: 0.9619\n",
            "Epoch 290/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9892\n",
            "Epoch 00290: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0158 - accuracy: 0.9892 - val_loss: 0.1410 - val_accuracy: 0.9640\n",
            "Epoch 291/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9896\n",
            "Epoch 00291: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0154 - accuracy: 0.9896 - val_loss: 0.1492 - val_accuracy: 0.9639\n",
            "Epoch 292/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9902\n",
            "Epoch 00292: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0136 - accuracy: 0.9901 - val_loss: 0.1591 - val_accuracy: 0.9640\n",
            "Epoch 293/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0155 - accuracy: 0.9894\n",
            "Epoch 00293: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0154 - accuracy: 0.9894 - val_loss: 0.1409 - val_accuracy: 0.9640\n",
            "Epoch 294/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9885\n",
            "Epoch 00294: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0173 - accuracy: 0.9886 - val_loss: 0.1494 - val_accuracy: 0.9638\n",
            "Epoch 295/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9893\n",
            "Epoch 00295: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0162 - accuracy: 0.9891 - val_loss: 0.1440 - val_accuracy: 0.9626\n",
            "Epoch 296/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9892\n",
            "Epoch 00296: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0156 - accuracy: 0.9892 - val_loss: 0.1531 - val_accuracy: 0.9640\n",
            "Epoch 297/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9894\n",
            "Epoch 00297: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0148 - accuracy: 0.9894 - val_loss: 0.1629 - val_accuracy: 0.9645\n",
            "Epoch 298/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9893\n",
            "Epoch 00298: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0148 - accuracy: 0.9893 - val_loss: 0.1565 - val_accuracy: 0.9644\n",
            "Epoch 299/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9903\n",
            "Epoch 00299: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0131 - accuracy: 0.9902 - val_loss: 0.1484 - val_accuracy: 0.9651\n",
            "Epoch 300/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9899\n",
            "Epoch 00300: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0137 - accuracy: 0.9899 - val_loss: 0.1628 - val_accuracy: 0.9641\n",
            "Epoch 301/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9898\n",
            "Epoch 00301: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0140 - accuracy: 0.9898 - val_loss: 0.1659 - val_accuracy: 0.9642\n",
            "Epoch 302/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9900\n",
            "Epoch 00302: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0128 - accuracy: 0.9900 - val_loss: 0.1773 - val_accuracy: 0.9643\n",
            "Epoch 303/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9899\n",
            "Epoch 00303: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0134 - accuracy: 0.9899 - val_loss: 0.1625 - val_accuracy: 0.9652\n",
            "Epoch 304/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9903\n",
            "Epoch 00304: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0130 - accuracy: 0.9902 - val_loss: 0.1783 - val_accuracy: 0.9634\n",
            "Epoch 305/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0125 - accuracy: 0.9903\n",
            "Epoch 00305: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0124 - accuracy: 0.9903 - val_loss: 0.1797 - val_accuracy: 0.9635\n",
            "Epoch 306/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0317 - accuracy: 0.9851\n",
            "Epoch 00306: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0318 - accuracy: 0.9851 - val_loss: 0.2510 - val_accuracy: 0.9423\n",
            "Epoch 307/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0828 - accuracy: 0.9714\n",
            "Epoch 00307: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0827 - accuracy: 0.9714 - val_loss: 0.1666 - val_accuracy: 0.9500\n",
            "Epoch 308/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0339 - accuracy: 0.9834\n",
            "Epoch 00308: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0340 - accuracy: 0.9834 - val_loss: 0.1444 - val_accuracy: 0.9594\n",
            "Epoch 309/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0305 - accuracy: 0.9852\n",
            "Epoch 00309: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0310 - accuracy: 0.9850 - val_loss: 0.1373 - val_accuracy: 0.9571\n",
            "Epoch 310/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0499 - accuracy: 0.9790\n",
            "Epoch 00310: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0520 - accuracy: 0.9786 - val_loss: 0.1739 - val_accuracy: 0.9468\n",
            "Epoch 311/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0459 - accuracy: 0.9799\n",
            "Epoch 00311: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 4s 31ms/step - loss: 0.0464 - accuracy: 0.9796 - val_loss: 0.1435 - val_accuracy: 0.9573\n",
            "Epoch 312/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9848\n",
            "Epoch 00312: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0302 - accuracy: 0.9848 - val_loss: 0.1333 - val_accuracy: 0.9614\n",
            "Epoch 313/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9855\n",
            "Epoch 00313: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0285 - accuracy: 0.9855 - val_loss: 0.1347 - val_accuracy: 0.9603\n",
            "Epoch 314/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.9871\n",
            "Epoch 00314: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0231 - accuracy: 0.9870 - val_loss: 0.1340 - val_accuracy: 0.9615\n",
            "Epoch 315/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9875\n",
            "Epoch 00315: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0200 - accuracy: 0.9875 - val_loss: 0.1442 - val_accuracy: 0.9624\n",
            "Epoch 316/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9878\n",
            "Epoch 00316: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0196 - accuracy: 0.9878 - val_loss: 0.1300 - val_accuracy: 0.9628\n",
            "Epoch 317/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9892\n",
            "Epoch 00317: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0159 - accuracy: 0.9892 - val_loss: 0.1639 - val_accuracy: 0.9632\n",
            "Epoch 318/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9894\n",
            "Epoch 00318: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0157 - accuracy: 0.9894 - val_loss: 0.1605 - val_accuracy: 0.9639\n",
            "Epoch 319/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9895\n",
            "Epoch 00319: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0156 - accuracy: 0.9895 - val_loss: 0.1565 - val_accuracy: 0.9646\n",
            "Epoch 320/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0144 - accuracy: 0.9897\n",
            "Epoch 00320: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0145 - accuracy: 0.9897 - val_loss: 0.1651 - val_accuracy: 0.9646\n",
            "Epoch 321/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9896\n",
            "Epoch 00321: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0148 - accuracy: 0.9895 - val_loss: 0.1742 - val_accuracy: 0.9632\n",
            "Epoch 322/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9752\n",
            "Epoch 00322: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0701 - accuracy: 0.9746 - val_loss: 0.2177 - val_accuracy: 0.9316\n",
            "Epoch 323/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0697 - accuracy: 0.9722\n",
            "Epoch 00323: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0692 - accuracy: 0.9723 - val_loss: 0.1399 - val_accuracy: 0.9561\n",
            "Epoch 324/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0310 - accuracy: 0.9849\n",
            "Epoch 00324: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0312 - accuracy: 0.9849 - val_loss: 0.1390 - val_accuracy: 0.9610\n",
            "Epoch 325/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0266 - accuracy: 0.9863\n",
            "Epoch 00325: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0264 - accuracy: 0.9863 - val_loss: 0.1332 - val_accuracy: 0.9601\n",
            "Epoch 326/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9858\n",
            "Epoch 00326: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0260 - accuracy: 0.9858 - val_loss: 0.1598 - val_accuracy: 0.9594\n",
            "Epoch 327/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0222 - accuracy: 0.9869\n",
            "Epoch 00327: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0229 - accuracy: 0.9866 - val_loss: 0.1881 - val_accuracy: 0.9585\n",
            "Epoch 328/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9883\n",
            "Epoch 00328: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0225 - accuracy: 0.9878 - val_loss: 0.1592 - val_accuracy: 0.9604\n",
            "Epoch 329/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0204 - accuracy: 0.9879\n",
            "Epoch 00329: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0204 - accuracy: 0.9879 - val_loss: 0.1650 - val_accuracy: 0.9608\n",
            "Epoch 330/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9832\n",
            "Epoch 00330: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0337 - accuracy: 0.9832 - val_loss: 0.1882 - val_accuracy: 0.9396\n",
            "Epoch 331/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0462 - accuracy: 0.9795\n",
            "Epoch 00331: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0455 - accuracy: 0.9797 - val_loss: 0.1212 - val_accuracy: 0.9617\n",
            "Epoch 332/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9867\n",
            "Epoch 00332: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0228 - accuracy: 0.9868 - val_loss: 0.1440 - val_accuracy: 0.9629\n",
            "Epoch 333/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9880\n",
            "Epoch 00333: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0194 - accuracy: 0.9881 - val_loss: 0.1492 - val_accuracy: 0.9622\n",
            "Epoch 334/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9885\n",
            "Epoch 00334: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0197 - accuracy: 0.9885 - val_loss: 0.1590 - val_accuracy: 0.9596\n",
            "Epoch 335/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9885\n",
            "Epoch 00335: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0191 - accuracy: 0.9886 - val_loss: 0.1443 - val_accuracy: 0.9630\n",
            "Epoch 336/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0199 - accuracy: 0.9881\n",
            "Epoch 00336: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0200 - accuracy: 0.9880 - val_loss: 0.1399 - val_accuracy: 0.9649\n",
            "Epoch 337/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9891\n",
            "Epoch 00337: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0164 - accuracy: 0.9891 - val_loss: 0.1475 - val_accuracy: 0.9641\n",
            "Epoch 338/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9888\n",
            "Epoch 00338: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0167 - accuracy: 0.9888 - val_loss: 0.1566 - val_accuracy: 0.9624\n",
            "Epoch 339/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9891\n",
            "Epoch 00339: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0161 - accuracy: 0.9891 - val_loss: 0.1687 - val_accuracy: 0.9614\n",
            "Epoch 340/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0223 - accuracy: 0.9872\n",
            "Epoch 00340: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0222 - accuracy: 0.9871 - val_loss: 0.1461 - val_accuracy: 0.9636\n",
            "Epoch 341/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9893\n",
            "Epoch 00341: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0158 - accuracy: 0.9893 - val_loss: 0.1572 - val_accuracy: 0.9631\n",
            "Epoch 342/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9883\n",
            "Epoch 00342: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0187 - accuracy: 0.9883 - val_loss: 0.1691 - val_accuracy: 0.9595\n",
            "Epoch 343/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0346 - accuracy: 0.9830\n",
            "Epoch 00343: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0345 - accuracy: 0.9830 - val_loss: 0.1634 - val_accuracy: 0.9547\n",
            "Epoch 344/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 0.9699\n",
            "Epoch 00344: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0827 - accuracy: 0.9702 - val_loss: 0.1420 - val_accuracy: 0.9529\n",
            "Epoch 345/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9848\n",
            "Epoch 00345: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0300 - accuracy: 0.9848 - val_loss: 0.1500 - val_accuracy: 0.9589\n",
            "Epoch 346/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9855\n",
            "Epoch 00346: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0283 - accuracy: 0.9855 - val_loss: 0.1449 - val_accuracy: 0.9564\n",
            "Epoch 347/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0490 - accuracy: 0.9815\n",
            "Epoch 00347: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0488 - accuracy: 0.9815 - val_loss: 0.1293 - val_accuracy: 0.9586\n",
            "Epoch 348/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0267 - accuracy: 0.9858\n",
            "Epoch 00348: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0266 - accuracy: 0.9859 - val_loss: 0.1351 - val_accuracy: 0.9602\n",
            "Epoch 349/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.9872\n",
            "Epoch 00349: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0226 - accuracy: 0.9871 - val_loss: 0.1482 - val_accuracy: 0.9610\n",
            "Epoch 350/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0194 - accuracy: 0.9880\n",
            "Epoch 00350: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0195 - accuracy: 0.9880 - val_loss: 0.1542 - val_accuracy: 0.9607\n",
            "Epoch 351/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9888\n",
            "Epoch 00351: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0176 - accuracy: 0.9888 - val_loss: 0.1275 - val_accuracy: 0.9638\n",
            "Epoch 352/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9878\n",
            "Epoch 00352: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0202 - accuracy: 0.9878 - val_loss: 0.1462 - val_accuracy: 0.9625\n",
            "Epoch 353/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9885\n",
            "Epoch 00353: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0180 - accuracy: 0.9885 - val_loss: 0.1467 - val_accuracy: 0.9641\n",
            "Epoch 354/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9883\n",
            "Epoch 00354: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0190 - accuracy: 0.9883 - val_loss: 0.1662 - val_accuracy: 0.9622\n",
            "Epoch 355/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9884\n",
            "Epoch 00355: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0183 - accuracy: 0.9884 - val_loss: 0.1618 - val_accuracy: 0.9606\n",
            "Epoch 356/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9883\n",
            "Epoch 00356: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0197 - accuracy: 0.9883 - val_loss: 0.1506 - val_accuracy: 0.9629\n",
            "Epoch 357/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9879\n",
            "Epoch 00357: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0194 - accuracy: 0.9880 - val_loss: 0.1496 - val_accuracy: 0.9621\n",
            "Epoch 358/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9888\n",
            "Epoch 00358: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0170 - accuracy: 0.9889 - val_loss: 0.1508 - val_accuracy: 0.9636\n",
            "Epoch 359/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9893\n",
            "Epoch 00359: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0157 - accuracy: 0.9893 - val_loss: 0.1602 - val_accuracy: 0.9625\n",
            "Epoch 360/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.9885\n",
            "Epoch 00360: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0177 - accuracy: 0.9886 - val_loss: 0.1573 - val_accuracy: 0.9632\n",
            "Epoch 361/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9891\n",
            "Epoch 00361: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0166 - accuracy: 0.9890 - val_loss: 0.1484 - val_accuracy: 0.9630\n",
            "Epoch 362/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9888\n",
            "Epoch 00362: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0174 - accuracy: 0.9887 - val_loss: 0.1501 - val_accuracy: 0.9643\n",
            "Epoch 363/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9860\n",
            "Epoch 00363: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0260 - accuracy: 0.9860 - val_loss: 0.1431 - val_accuracy: 0.9607\n",
            "Epoch 364/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9881\n",
            "Epoch 00364: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0188 - accuracy: 0.9882 - val_loss: 0.1363 - val_accuracy: 0.9649\n",
            "Epoch 365/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9890\n",
            "Epoch 00365: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 30ms/step - loss: 0.0166 - accuracy: 0.9890 - val_loss: 0.1628 - val_accuracy: 0.9623\n",
            "Epoch 366/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9884\n",
            "Epoch 00366: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0191 - accuracy: 0.9884 - val_loss: 0.1545 - val_accuracy: 0.9581\n",
            "Epoch 367/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9854\n",
            "Epoch 00367: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0284 - accuracy: 0.9855 - val_loss: 0.1296 - val_accuracy: 0.9639\n",
            "Epoch 368/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9885\n",
            "Epoch 00368: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0184 - accuracy: 0.9885 - val_loss: 0.1388 - val_accuracy: 0.9629\n",
            "Epoch 369/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9887\n",
            "Epoch 00369: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0173 - accuracy: 0.9887 - val_loss: 0.1322 - val_accuracy: 0.9645\n",
            "Epoch 370/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9893\n",
            "Epoch 00370: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0165 - accuracy: 0.9893 - val_loss: 0.1360 - val_accuracy: 0.9640\n",
            "Epoch 371/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9874\n",
            "Epoch 00371: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0217 - accuracy: 0.9874 - val_loss: 0.1488 - val_accuracy: 0.9636\n",
            "Epoch 372/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0270 - accuracy: 0.9857\n",
            "Epoch 00372: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0288 - accuracy: 0.9851 - val_loss: 0.1500 - val_accuracy: 0.9496\n",
            "Epoch 373/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.9434\n",
            "Epoch 00373: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.1588 - accuracy: 0.9444 - val_loss: 0.2145 - val_accuracy: 0.9362\n",
            "Epoch 374/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0890 - accuracy: 0.9683\n",
            "Epoch 00374: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0888 - accuracy: 0.9684 - val_loss: 0.2065 - val_accuracy: 0.9325\n",
            "Epoch 375/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0719 - accuracy: 0.9721\n",
            "Epoch 00375: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0718 - accuracy: 0.9720 - val_loss: 0.1491 - val_accuracy: 0.9481\n",
            "Epoch 376/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0564 - accuracy: 0.9760\n",
            "Epoch 00376: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0565 - accuracy: 0.9759 - val_loss: 0.1421 - val_accuracy: 0.9519\n",
            "Epoch 377/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.9802\n",
            "Epoch 00377: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0435 - accuracy: 0.9800 - val_loss: 0.1375 - val_accuracy: 0.9586\n",
            "Epoch 378/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9802\n",
            "Epoch 00378: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0490 - accuracy: 0.9802 - val_loss: 0.1351 - val_accuracy: 0.9594\n",
            "Epoch 379/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0290 - accuracy: 0.9853\n",
            "Epoch 00379: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0289 - accuracy: 0.9853 - val_loss: 0.1319 - val_accuracy: 0.9601\n",
            "Epoch 380/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0473 - accuracy: 0.9798\n",
            "Epoch 00380: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0491 - accuracy: 0.9791 - val_loss: 0.1738 - val_accuracy: 0.9332\n",
            "Epoch 381/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9759\n",
            "Epoch 00381: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0604 - accuracy: 0.9758 - val_loss: 0.1311 - val_accuracy: 0.9585\n",
            "Epoch 382/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9814\n",
            "Epoch 00382: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0473 - accuracy: 0.9813 - val_loss: 0.1372 - val_accuracy: 0.9596\n",
            "Epoch 383/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0358 - accuracy: 0.9830\n",
            "Epoch 00383: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0360 - accuracy: 0.9830 - val_loss: 0.1350 - val_accuracy: 0.9613\n",
            "Epoch 384/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9829\n",
            "Epoch 00384: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0365 - accuracy: 0.9830 - val_loss: 0.1390 - val_accuracy: 0.9592\n",
            "Epoch 385/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0294 - accuracy: 0.9847\n",
            "Epoch 00385: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0293 - accuracy: 0.9847 - val_loss: 0.1508 - val_accuracy: 0.9598\n",
            "Epoch 386/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9845\n",
            "Epoch 00386: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0297 - accuracy: 0.9845 - val_loss: 0.1575 - val_accuracy: 0.9602\n",
            "Epoch 387/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9862\n",
            "Epoch 00387: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0255 - accuracy: 0.9863 - val_loss: 0.1785 - val_accuracy: 0.9598\n",
            "Epoch 388/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9875\n",
            "Epoch 00388: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0212 - accuracy: 0.9875 - val_loss: 0.1718 - val_accuracy: 0.9596\n",
            "Epoch 389/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9876\n",
            "Epoch 00389: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0208 - accuracy: 0.9876 - val_loss: 0.1617 - val_accuracy: 0.9602\n",
            "Epoch 390/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9879\n",
            "Epoch 00390: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0202 - accuracy: 0.9879 - val_loss: 0.1617 - val_accuracy: 0.9616\n",
            "Epoch 391/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9875\n",
            "Epoch 00391: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0212 - accuracy: 0.9876 - val_loss: 0.1636 - val_accuracy: 0.9626\n",
            "Epoch 392/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0203 - accuracy: 0.9878\n",
            "Epoch 00392: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0202 - accuracy: 0.9878 - val_loss: 0.1607 - val_accuracy: 0.9616\n",
            "Epoch 393/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0184 - accuracy: 0.9883\n",
            "Epoch 00393: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0184 - accuracy: 0.9883 - val_loss: 0.1702 - val_accuracy: 0.9619\n",
            "Epoch 394/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0171 - accuracy: 0.9888\n",
            "Epoch 00394: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0171 - accuracy: 0.9888 - val_loss: 0.1625 - val_accuracy: 0.9631\n",
            "Epoch 395/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0181 - accuracy: 0.9885\n",
            "Epoch 00395: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0181 - accuracy: 0.9885 - val_loss: 0.1762 - val_accuracy: 0.9612\n",
            "Epoch 396/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0190 - accuracy: 0.9884\n",
            "Epoch 00396: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 28ms/step - loss: 0.0188 - accuracy: 0.9884 - val_loss: 0.1579 - val_accuracy: 0.9614\n",
            "Epoch 397/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.9889\n",
            "Epoch 00397: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0173 - accuracy: 0.9889 - val_loss: 0.1718 - val_accuracy: 0.9614\n",
            "Epoch 398/400\n",
            "113/114 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9889\n",
            "Epoch 00398: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0164 - accuracy: 0.9889 - val_loss: 0.1629 - val_accuracy: 0.9622\n",
            "Epoch 399/400\n",
            "111/114 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9896\n",
            "Epoch 00399: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0147 - accuracy: 0.9897 - val_loss: 0.1785 - val_accuracy: 0.9620\n",
            "Epoch 400/400\n",
            "112/114 [============================>.] - ETA: 0s - loss: 0.0166 - accuracy: 0.9893\n",
            "Epoch 00400: loss did not improve from 0.01188\n",
            "114/114 [==============================] - 3s 29ms/step - loss: 0.0166 - accuracy: 0.9892 - val_loss: 0.1570 - val_accuracy: 0.9623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcea6561748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONFNos0g25mT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x, y = valid_gen.__getitem__(4)\n",
        "result = model.predict(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOiWhR7l27s8",
        "colab_type": "code",
        "outputId": "f528bccd-4638-40a7-8deb-b13a1acd0a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "fig = plt.figure()\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.imshow(y[0])\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.imshow(result[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcea6b84e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAACuCAYAAADNhk2tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}